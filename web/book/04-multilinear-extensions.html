<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js navy">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Multilinear Extensions - Minimizing Trust, Maximizing Truth</title>


        <!-- Custom HTML head -->
        <script>
        window.MathJax = {
          tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]']],
            processEscapes: true,
            processEnvironments: true,
            packages: {'[+]': ['ams']}
          },
          options: {
            skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
          },
          loader: {
            load: ['[tex]/ams']
          }
        };
        </script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
        <script type="module">
          import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
          mermaid.initialize({ startOnLoad: false, theme: 'dark' });
        
          document.addEventListener('DOMContentLoaded', function() {
            // Transform mdBook's code blocks into Mermaid-compatible format
            document.querySelectorAll('pre code.language-mermaid').forEach(function(codeBlock) {
              const pre = codeBlock.parentElement;
              const div = document.createElement('div');
              div.className = 'mermaid';
              div.textContent = codeBlock.textContent;
              pre.parentElement.replaceChild(div, pre);
            });
            mermaid.run();
          });
        </script>

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="The Architecture of Verifiable Secrets - A comprehensive guide to Zero-Knowledge Proofs">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "navy";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('navy')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="introduction.html">Introduction</a></li><li class="chapter-item expanded affix "><li class="part-title">Foundations</li><li class="chapter-item expanded "><a href="01-the-trust-problem.html"><strong aria-hidden="true">1.</strong> The Trust Problem</a></li><li class="chapter-item expanded "><a href="02-the-alchemical-power-of-polynomials.html"><strong aria-hidden="true">2.</strong> The Alchemical Power of Polynomials</a></li><li class="chapter-item expanded "><a href="03-the-sum-check-protocol.html"><strong aria-hidden="true">3.</strong> The Sum-Check Protocol</a></li><li class="chapter-item expanded "><a href="04-multilinear-extensions.html" class="active"><strong aria-hidden="true">4.</strong> Multilinear Extensions</a></li><li class="chapter-item expanded "><a href="05-univariate-polynomials-and-finite-fields.html"><strong aria-hidden="true">5.</strong> Univariate Polynomials and Finite Fields</a></li><li class="chapter-item expanded "><a href="06-commitment-schemes.html"><strong aria-hidden="true">6.</strong> Commitment Schemes</a></li><li class="chapter-item expanded affix "><li class="part-title">Core Protocols</li><li class="chapter-item expanded "><a href="07-the-gkr-protocol.html"><strong aria-hidden="true">7.</strong> The GKR Protocol</a></li><li class="chapter-item expanded "><a href="08-from-circuits-to-polynomials.html"><strong aria-hidden="true">8.</strong> From Circuits to Polynomials</a></li><li class="chapter-item expanded "><a href="09-polynomial-commitment-schemes.html"><strong aria-hidden="true">9.</strong> Polynomial Commitment Schemes</a></li><li class="chapter-item expanded "><a href="10-hash-based-commitments-and-fri.html"><strong aria-hidden="true">10.</strong> Hash-Based Commitments and FRI</a></li><li class="chapter-item expanded affix "><li class="part-title">SNARK Construction</li><li class="chapter-item expanded "><a href="11-the-snark-recipe.html"><strong aria-hidden="true">11.</strong> The SNARK Recipe</a></li><li class="chapter-item expanded "><a href="12-groth16.html"><strong aria-hidden="true">12.</strong> Groth16</a></li><li class="chapter-item expanded "><a href="13-plonk.html"><strong aria-hidden="true">13.</strong> PLONK</a></li><li class="chapter-item expanded "><a href="14-lookup-arguments.html"><strong aria-hidden="true">14.</strong> Lookup Arguments</a></li><li class="chapter-item expanded "><a href="15-starks.html"><strong aria-hidden="true">15.</strong> STARKs</a></li><li class="chapter-item expanded affix "><li class="part-title">Zero-Knowledge</li><li class="chapter-item expanded "><a href="16-sigma-protocols.html"><strong aria-hidden="true">16.</strong> Sigma Protocols</a></li><li class="chapter-item expanded "><a href="17-the-zero-knowledge-property.html"><strong aria-hidden="true">17.</strong> The Zero-Knowledge Property</a></li><li class="chapter-item expanded "><a href="18-making-proofs-zero-knowledge.html"><strong aria-hidden="true">18.</strong> Making Proofs Zero-Knowledge</a></li><li class="chapter-item expanded affix "><li class="part-title">Advanced Topics</li><li class="chapter-item expanded "><a href="19-fast-sum-check-proving.html"><strong aria-hidden="true">19.</strong> Fast Sum-Check Proving</a></li><li class="chapter-item expanded "><a href="20-minimizing-commitment-costs.html"><strong aria-hidden="true">20.</strong> Minimizing Commitment Costs</a></li><li class="chapter-item expanded "><a href="21-the-two-classes-of-piops.html"><strong aria-hidden="true">21.</strong> The Two Classes of PIOPs</a></li><li class="chapter-item expanded "><a href="22-composition-and-recursion.html"><strong aria-hidden="true">22.</strong> Composition and Recursion</a></li><li class="chapter-item expanded "><a href="23-choosing-a-snark.html"><strong aria-hidden="true">23.</strong> Choosing a SNARK</a></li><li class="chapter-item expanded affix "><li class="part-title">Broader Context</li><li class="chapter-item expanded "><a href="24-mpc-and-zk-parallel-paths.html"><strong aria-hidden="true">24.</strong> MPC and ZK Parallel Paths</a></li><li class="chapter-item expanded "><a href="25-frontiers-and-open-problems.html"><strong aria-hidden="true">25.</strong> Frontiers and Open Problems</a></li><li class="chapter-item expanded "><a href="26-zk-in-the-cryptographic-landscape.html"><strong aria-hidden="true">26.</strong> ZK in the Cryptographic Landscape</a></li><li class="chapter-item expanded affix "><li class="part-title">Appendices</li><li class="chapter-item expanded "><a href="appendix-a-cryptographic-primitives.html"><strong aria-hidden="true">27.</strong> Cryptographic Primitives</a></li><li class="chapter-item expanded "><a href="appendix-b-historical-timeline.html"><strong aria-hidden="true">28.</strong> Historical Timeline</a></li><li class="chapter-item expanded "><a href="appendix-c-field-equations-cheat-sheet.html"><strong aria-hidden="true">29.</strong> Field Equations Cheat Sheet</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Minimizing Trust, Maximizing Truth</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/0xParti/zkBook" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        <a href="https://github.com/0xParti/zkBook/edit/main/web/src/04-multilinear-extensions.md" title="Suggest an edit" aria-label="Suggest an edit">
                            <i id="git-edit-button" class="fa fa-edit"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="chapter-4-multilinear-extensions"><a class="header" href="#chapter-4-multilinear-extensions">Chapter 4: Multilinear Extensions</a></h1>
<p>In 1971, the Mariner 9 probe became the first spacecraft to orbit another planet. Its mission: map the surface of Mars. But transmitting high-resolution images across 100 million miles of static-filled space was a nightmare. A single burst of cosmic noise could turn a crater into a glitch.</p>
<p>NASA didn't send raw pixels. They used a code developed years earlier by Irving Reed and David Muller: treat the pixel data as values and send evaluations of a <em>multivariate polynomial</em>. The Reed-Muller code could correct up to seven bit errors per 32-bit word. When Mariner 9 arrived to find Mars engulfed in a planet-wide dust storm, mission control reprogrammed the spacecraft from Earth and waited. When the dust cleared, the code delivered 7,329 images, mapping 85% of the Martian surface.</p>
<p>The same mathematical structure that gave humanity its first clear look at Mars now powers zero-knowledge proofs. Multivariate polynomials are robust: they let you reconstruct data even when parts are corrupted, or verify data by checking a single random point. This chapter develops that theory.</p>
<hr />
<p>How do you turn data into a polynomial?</p>
<p>The question is more subtle than it appears. Data is discrete: a list of values, a vector of field elements, the output of gates in a circuit. Polynomials are continuous mathematical objects defined over all of $\mathbb{F}^n$. Bridging this gap is the art of <strong>extension</strong>: taking a function defined on a finite set and stretching it to a polynomial defined everywhere.</p>
<p>The choice of extension matters enormously. A bad extension creates polynomials of exponential degree, destroying efficiency. A good extension preserves structure, enables fast algorithms, and makes random evaluation meaningful.</p>
<p>This chapter develops the theory of <strong>multilinear extensions</strong>: the canonical way to extend functions from the Boolean hypercube ${0,1}^n$ to polynomials over $\mathbb{F}^n$. These extensions are the workhorses of sum-check-based proof systems, encoding everything from circuit wire values to constraint satisfaction.</p>
<h2 id="the-boolean-hypercube"><a class="header" href="#the-boolean-hypercube">The Boolean Hypercube</a></h2>
<p>Consider the set ${0,1}^n$, all $n$-bit binary strings. This is the <strong>Boolean hypercube</strong>, and it contains exactly $2^n$ points.</p>
<pre><code>n = 2:
    (1,1)
     /  \
 (0,1)  (1,0)
     \  /
    (0,0)

n = 3: A cube with 8 vertices
</code></pre>
<p>Any function $f: {0,1}^n \to \mathbb{F}$ assigns a field element to each vertex of this hypercube. There are $2^n$ vertices, so $f$ is essentially a table of $2^n$ values.</p>
<p><strong>Examples</strong>:</p>
<ul>
<li>
<p>A vector $(v_1, \ldots, v_{2^n})$ can be viewed as $f(b) = v_{1 + \text{bin}(b)}$ where $\text{bin}(b)$ converts the bit string to an index</p>
</li>
<li>
<p>The output values of a layer of circuit gates</p>
</li>
<li>
<p>A database of $2^n$ records indexed by $n$-bit keys</p>
</li>
</ul>
<p>The hypercube is our <em>discrete</em> domain. We want a polynomial that agrees with $f$ on this domain but is defined everywhere.</p>
<h2 id="why-multilinear"><a class="header" href="#why-multilinear">Why Multilinear?</a></h2>
<p>In Chapter 2, we used univariate polynomials (Reed-Solomon). Why switch to multivariate now?</p>
<p><strong>The degree problem.</strong> If you encode $N = 2^{20}$ data points into a single-variable polynomial $p(x)$, that polynomial has degree about one million. Manipulating degree-million polynomials is expensive, requiring heavy FFT operations.</p>
<p><strong>The multilinear solution.</strong> If you encode the same $2^{20}$ points into a 20-variable multilinear polynomial, the degree in each variable is just 1. The total degree is only 20. By increasing the number of variables, we drastically lower the per-variable degree. This tradeoff (more variables, lower degree) enables the linear-time prover algorithms that power modern systems like HyperPlonk and Lasso, avoiding the expensive FFTs required by univariate approaches.</p>
<p>A polynomial in $n$ variables has terms like $X_1^{a_1} X_2^{a_2} \cdots X_n^{a_n}$ with various exponents. The <strong>degree</strong> in variable $X_i$ is the maximum exponent of $X_i$ across all terms.</p>
<p>A polynomial is <strong>multilinear</strong> if its degree in every variable is at most 1. Every term looks like a product of distinct variables (or subsets thereof):</p>
<p>$$\tilde{f}(X_1, \ldots, X_n) = \sum_{S \subseteq {1,\ldots,n}} c_S \prod_{i \in S} X_i$$</p>
<p>For example, with $n = 2$:
$$\tilde{f}(X_1, X_2) = c_\emptyset + c_{{1}} X_1 + c_{{2}} X_2 + c_{{1,2}} X_1 X_2$$</p>
<p>There are $2^n$ possible subsets $S$, hence $2^n$ coefficients. A multilinear polynomial in $n$ variables is fully specified by $2^n$ numbers, exactly matching the number of points in the hypercube.</p>
<p>This is not a coincidence. It's the key theorem:</p>
<p><strong>Theorem (Multilinear Extension).</strong> For any function $f: {0,1}^n \to \mathbb{F}$, there exists a unique multilinear polynomial $\tilde{f}: \mathbb{F}^n \to \mathbb{F}$ such that $\tilde{f}(b) = f(b)$ for all $b \in {0,1}^n$.</p>
<p>The function $\tilde{f}$ is called the <strong>multilinear extension (MLE)</strong> of $f$.</p>
<h2 id="constructing-the-multilinear-extension"><a class="header" href="#constructing-the-multilinear-extension">Constructing the Multilinear Extension</a></h2>
<p>The theorem claims uniqueness. How do we actually construct $\tilde{f}$?</p>
<h3 id="the-lagrange-basis"><a class="header" href="#the-lagrange-basis">The Lagrange Basis</a></h3>
<p>For each point $w \in {0,1}^n$, define the <strong>Lagrange basis polynomial</strong>:</p>
<p>$$L_w(X) = \prod_{i=1}^{n} \left( w_i \cdot X_i + (1 - w_i)(1 - X_i) \right)$$</p>
<p>This polynomial has a beautiful property: it equals 1 at $w$ and 0 at every other hypercube point.</p>
<p><strong>Why?</strong> At point $w$:</p>
<ul>
<li>
<p>If $w_i = 1$: the factor is $1 \cdot X_i + 0 \cdot (1 - X_i) = X_i$, which evaluates to $1$</p>
</li>
<li>
<p>If $w_i = 0$: the factor is $0 \cdot X_i + 1 \cdot (1 - X_i) = 1 - X_i$, which evaluates to $1$</p>
</li>
</ul>
<p>Every factor equals 1, so $L_w(w) = 1$.</p>
<p>At any other point $b \neq w$:</p>
<ul>
<li>
<p>There exists some coordinate $i$ where $b_i \neq w_i$</p>
</li>
<li>
<p>If $w_i = 1$ and $b_i = 0$: the factor $X_i$ evaluates to $0$</p>
</li>
<li>
<p>If $w_i = 0$ and $b_i = 1$: the factor $1 - X_i$ evaluates to $0$</p>
</li>
</ul>
<p>One factor is zero, so $L_w(b) = 0$.</p>
<h3 id="the-extension-formula"><a class="header" href="#the-extension-formula">The Extension Formula</a></h3>
<p>The multilinear extension is now simply:</p>
<p>$$\tilde{f}(X) = \sum_{w \in {0,1}^n} f(w) \cdot L_w(X)$$</p>
<p>At any hypercube point $b$:
$$\tilde{f}(b) = \sum_w f(w) \cdot L_w(b) = f(b) \cdot 1 + \sum_{w \neq b} f(w) \cdot 0 = f(b)$$</p>
<p>The extension agrees with $f$ on the hypercube. Since it's a sum of multilinear terms (each $L_w$ is multilinear), $\tilde{f}$ is multilinear.</p>
<h3 id="uniqueness"><a class="header" href="#uniqueness">Uniqueness</a></h3>
<p>If two multilinear polynomials agree on ${0,1}^n$, their difference is a multilinear polynomial that vanishes on all $2^n$ hypercube points. But a nonzero multilinear polynomial in $n$ variables has degree 1 in each variable; by Schwartz-Zippel, it can vanish on at most $1/|\mathbb{F}|$ fraction of points per variable. Over the hypercube, this means it can vanish on at most half the points in each direction, unless it's identically zero.</p>
<p>More directly: there are $2^n$ coefficients in a multilinear polynomial, and $2^n$ constraints (values at hypercube points). The system is determined. The unique solution is the MLE.</p>
<h2 id="the-equality-polynomial"><a class="header" href="#the-equality-polynomial">The Equality Polynomial</a></h2>
<p>One Lagrange basis polynomial deserves special attention: the <strong>equality polynomial</strong>.</p>
<p>$$\widetilde{\text{eq}}(X, Y) = \prod_{i=1}^{n} \left( X_i Y_i + (1 - X_i)(1 - Y_i) \right)$$</p>
<p>This is the MLE of the equality function:
$$\text{eq}(a, b) = \begin{cases} 1 &amp; \text{if } a = b \ 0 &amp; \text{otherwise} \end{cases}$$</p>
<p>for $a, b \in {0,1}^n$.</p>
<p>The Lagrange basis polynomials are just the equality polynomial with one input fixed:
$$L_w(X) = \widetilde{\text{eq}}(w, X)$$</p>
<p><strong>Why does this matter?</strong> The equality polynomial appears constantly in sum-check-based protocols. When we want to &quot;select&quot; a specific hypercube point using randomness, we evaluate $\widetilde{\text{eq}}(r, \cdot)$ at that point. Random $r \in \mathbb{F}^n$ gives a function that's negligibly small everywhere except near the hypercube points: a probabilistic selection mechanism.</p>
<h2 id="worked-example-a-2-variable-function"><a class="header" href="#worked-example-a-2-variable-function">Worked Example: A 2-Variable Function</a></h2>
<p>Let's trace through a complete example.</p>
<p><strong>The function</strong>: $f: {0,1}^2 \to \mathbb{F}$ defined by the table:</p>
<div class="table-wrapper"><table><thead><tr><th>$(X_1, X_2)$</th><th>$f(X_1, X_2)$</th></tr></thead><tbody>
<tr><td>$(0, 0)$</td><td>$3$</td></tr>
<tr><td>$(0, 1)$</td><td>$7$</td></tr>
<tr><td>$(1, 0)$</td><td>$2$</td></tr>
<tr><td>$(1, 1)$</td><td>$5$</td></tr>
</tbody></table>
</div>
<p><strong>The Lagrange basis polynomials</strong>:</p>
<p>$$L_{(0,0)}(X) = (1 - X_1)(1 - X_2)$$
$$L_{(0,1)}(X) = (1 - X_1) \cdot X_2$$
$$L_{(1,0)}(X) = X_1 \cdot (1 - X_2)$$
$$L_{(1,1)}(X) = X_1 \cdot X_2$$</p>
<p><strong>The multilinear extension</strong>:</p>
<p>$$\tilde{f}(X_1, X_2) = 3 \cdot (1-X_1)(1-X_2) + 7 \cdot (1-X_1)X_2 + 2 \cdot X_1(1-X_2) + 5 \cdot X_1 X_2$$</p>
<p>Expanding:</p>
<p>$$= 3(1 - X_1 - X_2 + X_1 X_2) + 7(X_2 - X_1 X_2) + 2(X_1 - X_1 X_2) + 5 X_1 X_2$$
$$= 3 - 3X_1 - 3X_2 + 3X_1X_2 + 7X_2 - 7X_1X_2 + 2X_1 - 2X_1X_2 + 5X_1X_2$$
$$= 3 + (-3 + 2)X_1 + (-3 + 7)X_2 + (3 - 7 - 2 + 5)X_1X_2$$
$$= 3 - X_1 + 4X_2 - X_1X_2$$</p>
<p><strong>Verification</strong>: Check that this matches the table:</p>
<ul>
<li>
<p>$\tilde{f}(0,0) = 3 - 0 + 0 - 0 = 3$ (matches)</p>
</li>
<li>
<p>$\tilde{f}(0,1) = 3 - 0 + 4 - 0 = 7$ (matches)</p>
</li>
<li>
<p>$\tilde{f}(1,0) = 3 - 1 + 0 - 0 = 2$ (matches)</p>
</li>
<li>
<p>$\tilde{f}(1,1) = 3 - 1 + 4 - 1 = 5$ (matches)</p>
</li>
</ul>
<p><strong>Evaluation at a random point</strong>: What is $\tilde{f}(0.5, 0.3)$?
$$\tilde{f}(0.5, 0.3) = 3 - 0.5 + 4(0.3) - (0.5)(0.3) = 3 - 0.5 + 1.2 - 0.15 = 3.55$$</p>
<p>This value has no &quot;meaning&quot; on the hypercube; $(0.5, 0.3)$ isn't a Boolean point. But this is exactly what we want: the polynomial is defined everywhere, and random evaluation is the key to probabilistic verification.</p>
<h2 id="efficient-evaluation"><a class="header" href="#efficient-evaluation">Efficient Evaluation</a></h2>
<p>Given the table of values ${f(w) : w \in {0,1}^n}$ and a query point $r \in \mathbb{F}^n$, how fast can we compute $\tilde{f}(r)$?</p>
<p><strong>Naive approach</strong>: Sum over all $2^n$ terms:
$$\tilde{f}(r) = \sum_{w \in {0,1}^n} f(w) \cdot L_w(r)$$</p>
<p>Each $L_w(r)$ takes $O(n)$ to compute. Total: $O(n \cdot 2^n)$.</p>
<p><strong>Better: Streaming evaluation</strong>. We can compute $\tilde{f}(r)$ in $O(2^n)$ time with the following observation.</p>
<p>Define $T_k$ as the &quot;partial extension&quot; using only the first $k$ variables of $r$:</p>
<p>$$T_k(x_{k+1}, \ldots, x_n) = \sum_{(b_1, \ldots, b_k) \in {0,1}^k} f(b_1, \ldots, b_k, x_{k+1}, \ldots, x_n) \cdot \prod_{i=1}^{k} L_{b_i}(r_i)$$</p>
<p>At $k = 0$: $T_0 = f$ (the original table).</p>
<p>At $k = n$: $T_n = \tilde{f}(r)$ (a single value).</p>
<p>The recursion from $T_k$ to $T_{k+1}$:</p>
<p>$$T_{k+1}(x_{k+2}, \ldots, x_n) = (1 - r_{k+1}) \cdot T_k(0, x_{k+2}, \ldots) + r_{k+1} \cdot T_k(1, x_{k+2}, \ldots)$$</p>
<p>Each step halves the table size. Total work: $2^n + 2^{n-1} + \cdots + 1 = O(2^n)$.</p>
<p>This is linear in the table size, optimal for any algorithm that must touch all values.</p>
<h3 id="worked-example-streaming-evaluation"><a class="header" href="#worked-example-streaming-evaluation">Worked Example: Streaming Evaluation</a></h3>
<p>Let's trace through this algorithm with our earlier function $f: {0,1}^2 \to \mathbb{F}$:</p>
<div class="table-wrapper"><table><thead><tr><th>$(b_1, b_2)$</th><th>$f(b_1, b_2)$</th></tr></thead><tbody>
<tr><td>$(0, 0)$</td><td>$3$</td></tr>
<tr><td>$(0, 1)$</td><td>$7$</td></tr>
<tr><td>$(1, 0)$</td><td>$2$</td></tr>
<tr><td>$(1, 1)$</td><td>$5$</td></tr>
</tbody></table>
</div>
<p>We want to compute $\tilde{f}(r_1, r_2)$ at the point $r = (0.4, 0.7)$.</p>
<p><strong>Step 0: Initialize $T_0$</strong></p>
<p>$T_0$ is just the original table, a function of both variables:
$$T_0(x_1, x_2) = f(x_1, x_2)$$</p>
<p>Think of it as four values indexed by $(x_1, x_2) \in {0,1}^2$:
$$T_0 = \begin{array}{c|cc} &amp; x_2=0 &amp; x_2=1 \ x_1=0 &amp; 3 &amp; 7 \ x_1=1 &amp; 2 &amp; 5 \end{array}$$</p>
<p><strong>Step 1: Compute $T_1$ by &quot;folding in&quot; $r_1 = 0.4$</strong></p>
<p>The recursion says:
$$T_1(x_2) = (1 - r_1) \cdot T_0(0, x_2) + r_1 \cdot T_0(1, x_2)$$</p>
<p>This is a weighted combination of the two rows, using $1 - r_1 = 0.6$ and $r_1 = 0.4$:</p>
<ul>
<li>
<p>$T_1(0) = 0.6 \cdot T_0(0,0) + 0.4 \cdot T_0(1,0) = 0.6 \cdot 3 + 0.4 \cdot 2 = 1.8 + 0.8 = 2.6$</p>
</li>
<li>
<p>$T_1(1) = 0.6 \cdot T_0(0,1) + 0.4 \cdot T_0(1,1) = 0.6 \cdot 7 + 0.4 \cdot 5 = 4.2 + 2.0 = 6.2$</p>
</li>
</ul>
<p>The table has shrunk from 4 values to 2 values: $T_1 = [2.6, 6.2]$.</p>
<p><strong>Step 2: Compute $T_2$ by &quot;folding in&quot; $r_2 = 0.7$</strong></p>
<p>$$T_2 = (1 - r_2) \cdot T_1(0) + r_2 \cdot T_1(1) = 0.3 \cdot 2.6 + 0.7 \cdot 6.2 = 0.78 + 4.34 = 5.12$$</p>
<p>The table has shrunk from 2 values to 1 value. This single value is $\tilde{f}(0.4, 0.7) = 5.12$.</p>
<p><strong>Verification</strong>: Using the explicit formula $\tilde{f}(X_1, X_2) = 3 - X_1 + 4X_2 - X_1X_2$:
$$\tilde{f}(0.4, 0.7) = 3 - 0.4 + 4(0.7) - (0.4)(0.7) = 3 - 0.4 + 2.8 - 0.28 = 5.12 \checkmark$$</p>
<p><strong>Why does this work?</strong> The key insight is that the Lagrange basis factorizes:
$$L_{(b_1, b_2)}(r_1, r_2) = L_{b_1}(r_1) \cdot L_{b_2}(r_2)$$</p>
<p>where $L_0(r) = 1 - r$ and $L_1(r) = r$. So when we compute the weighted sum in Step 1, we're effectively &quot;absorbing&quot; the $L_{b_1}(r_1)$ factor from each term. What remains is a smaller sum over just $b_2$, which we handle in Step 2.</p>
<p><strong>The Tournament Bracket.</strong> Think of a single-elimination tournament with $2^n$ players. In each round, pairs compete and half are eliminated. After $n$ rounds, one champion remains. The streaming algorithm works the same way: $2^n$ table entries enter, each round uses a random weight to combine pairs, and after $n$ rounds a single evaluation emerges. The tournament bracket is the structure of multilinear computation.</p>
<p>This pattern of using a random challenge to collapse pairs of values and halving the problem size will reappear throughout this book. In Chapter 10 (FRI), we'll name it <strong>folding</strong> and see it as one of the central techniques in zero-knowledge proofs.</p>
<h3 id="code-streaming-mle-evaluation"><a class="header" href="#code-streaming-mle-evaluation">Code: Streaming MLE Evaluation</a></h3>
<p>The algorithm above translates directly to code. Each coordinate of $r$ folds the table in half.</p>
<pre><code class="language-python">def mle_eval(table, r):
    &quot;&quot;&quot;
    Evaluate the multilinear extension of `table` at point `r`.

    Args:
        table: List of 2^n field elements (the function values on hypercube)
        r: Tuple of n coordinates (r_1, ..., r_n)

    Returns: The value of the MLE at r
    &quot;&quot;&quot;
    T = table.copy()

    for r_i in r:
        half = len(T) // 2
        # Fold: T'[j] = (1 - r_i) * T[2j] + r_i * T[2j+1]
        T = [(1 - r_i) * T[2*j] + r_i * T[2*j + 1]
             for j in range(half)]

    return T[0]  # Single value remains

# Example from the worked example above
table = [3, 7, 2, 5]  # f(0,0)=3, f(0,1)=7, f(1,0)=2, f(1,1)=5
r = (0.4, 0.7)

result = mle_eval(table, r)
print(f&quot;Streaming: MLE({r}) = {result}&quot;)

# Verify against explicit formula: f(X1,X2) = 3 - X1 + 4*X2 - X1*X2
explicit = 3 - 0.4 + 4*0.7 - 0.4*0.7
print(f&quot;Explicit:  MLE({r}) = {explicit}&quot;)
</code></pre>
<p>Output:</p>
<pre><code>Streaming: MLE((0.4, 0.7)) = 5.12
Explicit:  MLE((0.4, 0.7)) = 5.12
</code></pre>
<p>The streaming algorithm touches each table entry exactly once. For a table of size $N = 2^n$, total work is $N/2 + N/4 + \cdots + 1 = N - 1 = O(N)$.</p>
<h2 id="tensor-product-structure"><a class="header" href="#tensor-product-structure">Tensor Product Structure</a></h2>
<p>The Lagrange basis has a beautiful factorization that underlies many fast algorithms.</p>
<p>For $w = (w_1, \ldots, w_n) \in {0,1}^n$:</p>
<p>$$L_w(r_1, \ldots, r_n) = \prod_{i=1}^{n} L_{w_i}(r_i)$$</p>
<p>where $L_0(r_i) = 1 - r_i$ and $L_1(r_i) = r_i$.</p>
<p>This is a <strong>tensor product</strong>: the $n$-variable basis factorizes into a product of $n$ one-variable bases.</p>
<p><strong>Consequence</strong>: The vector of all $2^n$ Lagrange evaluations $(L_w(r))_{w \in {0,1}^n}$ is the tensor product:</p>
<p>$$(L_0(r_1), L_1(r_1)) \otimes (L_0(r_2), L_1(r_2)) \otimes \cdots \otimes (L_0(r_n), L_1(r_n))$$</p>
<p>Computing this tensor product directly takes $O(2^n)$ operations. The structure enables:</p>
<ul>
<li>
<p>Fast evaluation via the streaming algorithm above</p>
</li>
<li>
<p>Efficient prover algorithms for sum-check (Chapter 19)</p>
</li>
<li>
<p>Recursive proof constructions</p>
</li>
</ul>
<h2 id="multilinear-extensions-of-functions-on-larger-domains"><a class="header" href="#multilinear-extensions-of-functions-on-larger-domains">Multilinear Extensions of Functions on Larger Domains</a></h2>
<p>What if our function isn't defined on ${0,1}^n$?</p>
<p>Suppose $f: {0, 1, \ldots, m-1} \to \mathbb{F}$ for some $m = 2^n$. We can <em>interpret</em> the domain as ${0,1}^n$ via binary encoding:</p>
<p>$$\tilde{f}(X_1, \ldots, X_n) = \text{MLE of } (k \mapsto f(k)) \text{ with } k = \sum_i 2^{i-1} X_i$$</p>
<p>Any function on a power-of-two domain has a natural multilinear extension.</p>
<p>For domains not of size $2^n$, we can pad with zeros or use more sophisticated encodings. The key insight: as long as the domain is <em>finite</em>, we can always encode it in binary and take the MLE.</p>
<h2 id="connection-to-sum-check"><a class="header" href="#connection-to-sum-check">Connection to Sum-Check</a></h2>
<p>The sum-check protocol (Chapter 3) proves claims of the form:</p>
<p>$$H = \sum_{b \in {0,1}^n} g(b)$$</p>
<p>for some polynomial $g$. When $g$ is the multilinear extension of a function, this sum is just... the sum of all function values.</p>
<p><strong>Example</strong>: Prove that a vector $(v_1, \ldots, v_N)$ with $N = 2^n$ sums to a claimed value $H$.</p>
<p>Let $\tilde{v}$ be the MLE encoding the vector. Then:
$$\sum_{b \in {0,1}^n} \tilde{v}(b) = \sum_{i=1}^{N} v_i = H$$</p>
<p>Sum-check verifies this identity without the verifier seeing all of $v$. The protocol reduces the sum to a single random evaluation $\tilde{v}(r)$, which the prover supplies (with a commitment proof).</p>
<p>This is the bridge from &quot;data&quot; to &quot;proof&quot;: encode data as an MLE, verify properties via sum-check, bind via polynomial commitment.</p>
<h2 id="the-golden-link-evaluations--coordinates"><a class="header" href="#the-golden-link-evaluations--coordinates">The Golden Link: Evaluations = Coordinates</a></h2>
<p>Here's a perspective that clarifies many constructions.</p>
<p>A multilinear polynomial $\tilde{f}$ has $2^n$ coefficients (the $c_S$ values in the monomial expansion $\sum_S c_S \prod_{i \in S} X_i$). These coefficients live in an abstract &quot;coefficient space.&quot;</p>
<p>But $\tilde{f}$ also has $2^n$ evaluations on the hypercube. These evaluations are just $f(w)$, the original table values you started with.</p>
<p>These are not the same numbers. The table entry $f(0,0) = 3$ in our worked example is not a coefficient of the polynomial. The polynomial $\tilde{f}(X_1, X_2) = 3 - X_1 + 4X_2 - X_1X_2$ has coefficients ${3, -1, 4, -1}$, while the table values are ${3, 7, 2, 5}$. They're related by the Lagrange interpolation formula.</p>
<p><strong>The key insight</strong>: For multilinear polynomials, the evaluation table <em>is</em> a complete description. You can recover coefficients from evaluations and vice versa. They're just two bases for the same $2^n$-dimensional vector space.</p>
<p>The transformation between bases is exactly the Lagrange interpolation formula and its inverse. Both can be computed in $O(2^n)$ time.</p>
<p>This means:</p>
<ul>
<li>
<p>Committing to a multilinear polynomial = committing to its evaluation table</p>
</li>
<li>
<p>Evaluating at a random point = a linear combination of table entries</p>
</li>
<li>
<p>Sum-check over an MLE = reasoning about the table entries</p>
</li>
</ul>
<p>The polynomial structure enables <em>random access</em> to compressed representations of the table. That's the source of succinctness.</p>
<h3 id="polynomial-evaluation-as-inner-product"><a class="header" href="#polynomial-evaluation-as-inner-product">Polynomial Evaluation as Inner Product</a></h3>
<p>There's a beautiful way to see this algebraically: <strong>polynomial evaluation is an inner product</strong>.</p>
<p>For a multilinear polynomial, the evaluation at any point $r$ is:</p>
<p>$$\tilde{f}(r) = \sum_{w \in {0,1}^n} f(w) \cdot L_w(r) = \langle \vec{f}, \vec{L}(r) \rangle$$</p>
<p>where $\vec{f} = (f(w))<em>{w \in {0,1}^n}$ is the table of values and $\vec{L}(r) = (L_w(r))</em>{w \in {0,1}^n}$ is the vector of Lagrange basis evaluations at $r$.</p>
<p>This linear algebra perspective is surprisingly powerful, and it sparked what researchers call the &quot;Sum-Check Renaissance&quot; in the 2010s. For decades, sum-check was seen as a beautiful theoretical result with limited practical use. Then came the realization: if you express polynomial evaluation as an inner product, and you have efficient inner product arguments, you can build practical proof systems entirely from sum-check and linear algebra. No FFTs, no trusted setups, just vectors and dot products. Systems like Spartan, HyperPlonk, and Lasso all exploit this insight.</p>
<p>The consequences are immediate:</p>
<ul>
<li><strong>Commitment</strong>: Committing to $\tilde{f}$ means committing to the vector $\vec{f}$</li>
<li><strong>Evaluation proof</strong>: Proving $\tilde{f}(r) = y$ means proving an inner product claim $\langle \vec{f}, \vec{L}(r) \rangle = y$</li>
<li><strong>The verifier knows $\vec{L}(r)$</strong>: Given $r$, anyone can compute the Lagrange evaluations</li>
</ul>
<p>This reduces polynomial evaluation proofs to inner product proofs, and inner products interact beautifully with homomorphic commitments. We'll exploit this connection in Chapters 6 and 9.</p>
<h2 id="key-takeaways"><a class="header" href="#key-takeaways">Key Takeaways</a></h2>
<ol>
<li>
<p><strong>The Boolean hypercube</strong> ${0,1}^n$ is the natural domain for multilinear polynomials. It has $2^n$ points.</p>
</li>
<li>
<p><strong>Multilinear extension (MLE)</strong>: The unique polynomial of degree at most 1 in each variable that agrees with $f$ on the hypercube.</p>
</li>
<li>
<p><strong>Lagrange basis polynomials</strong> $L_w(X)$ equal 1 at $w$ and 0 elsewhere. The MLE is $\tilde{f}(X) = \sum_w f(w) \cdot L_w(X)$.</p>
</li>
<li>
<p><strong>The equality polynomial</strong> $\widetilde{\text{eq}}(X, Y)$ is the MLE of the equality indicator. Lagrange bases are $L_w(X) = \widetilde{\text{eq}}(w, X)$.</p>
</li>
<li>
<p><strong>Tensor product structure</strong>: $L_w(r) = \prod_i L_{w_i}(r_i)$. The basis factorizes, enabling fast algorithms.</p>
</li>
<li>
<p><strong>Efficient evaluation</strong>: Given the table and a point, compute the MLE in $O(2^n)$ time via streaming.</p>
</li>
<li>
<p><strong>Sum over the hypercube</strong>: $\sum_b \tilde{f}(b) = \sum_w f(w)$. Sum-check verifies such sums efficiently.</p>
</li>
<li>
<p><strong>Evaluations = coefficients</strong>: For MLEs, the table of values completely determines the polynomial. They're dual representations.</p>
</li>
<li>
<p><strong>Binary encoding</strong>: Any function on ${0, \ldots, 2^n - 1}$ can be encoded as a function on ${0,1}^n$, then extended multilinearly.</p>
</li>
<li>
<p><strong>The bridge to proofs</strong>: MLEs encode data; sum-check verifies properties; polynomial commitment binds the prover. This trinity underlies sum-check-based SNARKs.</p>
</li>
</ol>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="03-the-sum-check-protocol.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="05-univariate-polynomials-and-finite-fields.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="03-the-sum-check-protocol.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="05-univariate-polynomials-and-finite-fields.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script type="text/javascript">
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->


    </body>
</html>
